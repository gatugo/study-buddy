import os
from pathlib import Path
from dotenv import load_dotenv
import google.generativeai as genai
import ollama

load_dotenv()  # Load API Key from .env

# --- MODEL CONFIGURATION ---
# Change these to swap models without touching any other code.
LOCAL_TEXT_MODEL = "llama3.1"         # Logic Brain â€” text & code
LOCAL_VISION_MODEL = "qwen2.5vl:3b"  # Vision Brain â€” images, OCR, screenshots
CLOUD_MODEL = "gemini-1.5-flash"     # Cloud handles both text + vision natively

GEMINI_KEY = os.getenv("GEMINI_API_KEY")
SYSTEM_PROMPT_PATH = "TUTOR_PROMPT.md"


class HybridTutor:
    def __init__(self):
        self.mode = "local"
        self.history = []
        self.system_prompt = self.load_system_prompt()
        self.gemini_chat = None
        self.gemini_model = None

    def load_system_prompt(self):
        if os.path.exists(SYSTEM_PROMPT_PATH):
            with open(SYSTEM_PROMPT_PATH, "r") as f:
                return f.read()
        return "You are a helpful coding tutor."

    # â”€â”€ Cloud Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def setup_gemini(self):
        if not GEMINI_KEY or "PASTE_YOUR_KEY" in GEMINI_KEY:
            print("âš ï¸ Error: GEMINI_API_KEY missing in .env file.")
            return False
        try:
            genai.configure(api_key=GEMINI_KEY)
            self.gemini_model = genai.GenerativeModel(CLOUD_MODEL)
            self.gemini_chat = self.gemini_model.start_chat(history=[])
            return True
        except Exception as e:
            print(f"âŒ Connection Error: {e}")
            return False

    # â”€â”€ Text Brains â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def chat_local(self, user_input):
        messages = [{'role': 'system', 'content': self.system_prompt}] + self.history
        messages.append({'role': 'user', 'content': user_input})
        print(f"\nğŸ§  (Local {LOCAL_TEXT_MODEL}) Thinking...", end="", flush=True)
        response = ollama.chat(model=LOCAL_TEXT_MODEL, messages=messages)
        return response['message']['content']

    def chat_cloud(self, user_input):
        print(f"\nâ˜ï¸ (Cloud {CLOUD_MODEL}) Thinking...", end="", flush=True)
        full_prompt = f"{self.system_prompt}\n\nUSER QUESTION: {user_input}"
        response = self.gemini_chat.send_message(full_prompt)
        return response.text

    # â”€â”€ Vision Brains (Split-Brain) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def chat_vision_local(self, image_path, question):
        """Send image + prompt to the local vision model via Ollama."""
        abs_path = str(Path(image_path).resolve())
        if not Path(abs_path).exists():
            return f"âŒ Image not found: {image_path}"

        print(f"\nğŸ‘ï¸ (Local {LOCAL_VISION_MODEL}) Analyzing image...", end="", flush=True)
        messages = [
            {
                'role': 'user',
                'content': question or "Describe this image in detail.",
                'images': [abs_path],
            }
        ]
        response = ollama.chat(model=LOCAL_VISION_MODEL, messages=messages)
        return response['message']['content']

    def chat_vision_cloud(self, image_path, question):
        """Send image + prompt to Gemini Flash (already multimodal)."""
        abs_path = str(Path(image_path).resolve())
        if not Path(abs_path).exists():
            return f"âŒ Image not found: {image_path}"

        print(f"\nâ˜ï¸ğŸ‘ï¸ (Cloud {CLOUD_MODEL} Vision) Analyzing image...", end="", flush=True)
        try:
            uploaded = genai.upload_file(abs_path)
            prompt = f"{self.system_prompt}\n\nUSER QUESTION about the image: {question or 'Describe this image in detail.'}"
            response = self.gemini_model.generate_content([prompt, uploaded])
            return response.text
        except Exception as e:
            return f"âŒ Cloud vision error: {e}"

    # â”€â”€ Input Routing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def parse_img_command(self, user_input):
        """Parse 'img <path> <question>' â€” returns (path, question) or None."""
        if not user_input.lower().startswith("img "):
            return None
        parts = user_input[4:].strip()
        if not parts:
            return None

        # Handle quoted paths: img "path with spaces.png" question
        if parts.startswith('"'):
            end_quote = parts.find('"', 1)
            if end_quote != -1:
                img_path = parts[1:end_quote]
                question = parts[end_quote + 1:].strip()
                return (img_path, question)

        # Simple split: img path.png question here
        tokens = parts.split(maxsplit=1)
        img_path = tokens[0]
        question = tokens[1] if len(tokens) > 1 else ""
        return (img_path, question)

    # â”€â”€ Commands â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def show_models(self):
        """Print currently active models."""
        mode_label = "â˜ï¸ CLOUD" if self.mode == "cloud" else "ğŸ§  LOCAL"
        print(f"\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"â”‚ Mode:         {mode_label}")
        print(f"â”‚ Text Brain:   {CLOUD_MODEL if self.mode == 'cloud' else LOCAL_TEXT_MODEL}")
        print(f"â”‚ Vision Brain: {CLOUD_MODEL if self.mode == 'cloud' else LOCAL_VISION_MODEL}")
        print(f"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    def show_help(self):
        """Print available commands."""
        print("\nğŸ’¡ Commands:")
        print("  (just type)           â†’ Ask any text/code question")
        print("  img <path> <question> â†’ Send an image to the vision brain")
        print("  RESCUE                â†’ Get full working solution immediately")
        print("  switch                â†’ Toggle Cloud â†” Local mode")
        print("  models                â†’ Show active model configuration")
        print("  help                  â†’ Show this help")
        print("  quit                  â†’ Exit the tutor")

    # â”€â”€ Main Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def start(self):
        print("ğŸ¤– Antigravity Tutor (Split-Brain Engine)")
        print("   Text Brain  â†’ code & reasoning")
        print("   Vision Brain â†’ images, OCR, screenshots\n")

        choice = input("Select Brain: [1] Google Gemini (Cloud)  [2] Llama + Qwen (Local): ")
        if choice == '1':
            if self.setup_gemini():
                self.mode = "cloud"
                print(f"âœ… Connected to Cloud ({CLOUD_MODEL}).")
            else:
                self.mode = "local"
                print("âš ï¸ Fallback to Local.")
        else:
            self.mode = "local"
            print(f"âœ… Connected to Local (Text: {LOCAL_TEXT_MODEL} | Vision: {LOCAL_VISION_MODEL}).")

        self.show_help()

        while True:
            user_input = input("\nYou: ").strip()
            if not user_input:
                continue
            if user_input.lower() in ['quit', 'exit']:
                print("ğŸ‘‹ See you next time!")
                break
            if user_input.lower() == 'switch':
                if self.mode == "local":
                    if self.setup_gemini():
                        self.mode = "cloud"
                    else:
                        print("âš ï¸ Could not connect to cloud. Staying local.")
                        continue
                else:
                    self.mode = "local"
                print(f"ğŸ”„ Switched to {self.mode.upper()} mode.")
                self.show_models()
                continue
            if user_input.lower() == 'models':
                self.show_models()
                continue
            if user_input.lower() == 'help':
                self.show_help()
                continue

            try:
                # â”€â”€ Vision routing â”€â”€
                img_cmd = self.parse_img_command(user_input)
                if img_cmd:
                    img_path, question = img_cmd
                    if self.mode == "cloud":
                        response = self.chat_vision_cloud(img_path, question)
                    else:
                        response = self.chat_vision_local(img_path, question)
                else:
                    # â”€â”€ Text routing â”€â”€
                    if self.mode == "cloud":
                        response = self.chat_cloud(user_input)
                    else:
                        response = self.chat_local(user_input)

                print(f"\nTutor: {response}")
                self.history.append({'role': 'user', 'content': user_input})
                self.history.append({'role': 'assistant', 'content': response})

            except Exception as e:
                print(f"âŒ Error: {e}")


if __name__ == "__main__":
    app = HybridTutor()
    app.start()
